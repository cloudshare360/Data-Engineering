Workday
flatfiles
SAP HANA
Suvery

AWS data lake (source1 (xml), source (json), source3 txt files)

raw --> dumping of files.
curated --> etl jobs (dimensions and fact tables)  stage tables. apache pipelines.5 hours
processed 1 hour final layer. s3 --> data

to parquet
STARBURST (data bricks) DATABRICKS SQL WAREHOUSE (nOTEBOOKS)

snowflake
redshift --> tableau.(live vs extract)


cus id    cus name  cus phno   cus email
1			

fact1

p1 cust id prod id time id location id    no. of orders
1    200     300    june 2025    700   50  


